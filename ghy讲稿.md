大家好，我介绍的主题是目录式缓存一致性协议以及一种对它和广播/侦听协议的性能进行比较的方法。我的内容有三部分，首先我会介绍为什么需要目录式协议，它克服了广播/侦听协议的哪些缺陷。之后我会用两个实例介绍目录式协议的工作方式，最后我会介绍对不同缓存一致性协议性能进行量化比较的一种方法。

上一个同学已经介绍了广播侦听协议，然而如果我们想把64或更多个单处理器核心集成到一起实现一个可以提供**共享存储编程模型**的系统，这样的系统称为大规模多处理器系统，在这样的系统上应用广播侦听协议是会遇到一些问题的，我把这些问题总结为了三点：

- 第一点：**总线由于物理约束而难以扩展支持大规模多处理器系统。**之前的同学讲到广播侦听协议一般是配合总线形式的处理器互联使用的，如果一个chip上集成的处理器过多，就会导致片上总线的长度过长，产生无法忽视的时钟偏移，最后导致无法实现这样的系统。

- 第二点：**一致性操作之间以及一致性操作与外存访问之间竞争总线带宽。**这是由于总线的特点造成的，假设处理器1发出了一个无效块的一致性请求，那么这个请求需要在总线上传递给所有的处理器。这就导致其它处理器的总线请求需要等待。当总线上的处理器个数较少时，这个影响不是很严重，因为总线事务本身就是很少的。然而总线请求数量至少随着处理器个数的增多线性增长，随着处理器的增多，总线上会产生拥堵，降低处理器的ipc。
- 第三点：**一致性控制器与处理器竞争cache访问带宽。**每个处理器都有一个一致性控制器，用来侦听总线请求。如果总线上有一个别的处理器发出的无效块的请求，那么这个一致性控制器就要访问cache，查询cache里是否有这个block，如果有就无效掉。cache一般是单端口RAM结构，一个时刻只能有一个master读，所以一致性控制器读的时候处理器核心就读不了，造成流水线暂停。随着总线事务的增多，这个问题会越来越严重。

我们发现后两个问题是由于**所有**一致性操作都需要发送给**每一个**处理器所造成的，而第一个问题则是由于总线这个互联结构物理上扩展性很弱。

为了解决这些问题，我们一方面要使用一种线延迟短的互联结构，另一方面要**只对需要进行一致性操作的处理器发送一致性请求。**为了实现针对性发送请求，我们需要一个数据结构来保存对每一个数据块，哪个cache拥有该数据块的副本，以及缓存中该数据块的状态，这个数据结构称之为目录。最极端情况下，一个数据块被所有的处理器共享，那么如果要无效掉这个块就需要对所有处理器发送请求，这就相当于广播/侦听了，然而在充分调优的程序中，数据共享大多数只发生在只读数据，读写块很少共享。

下面我们通过两个例子来理解目录式协议的工作过程，先看一个读实例。系统中有三个处理器和一个目录。块B在P2的cache中并且是Modify状态。目录中保存块B的信息，即它只在P2中并且是M状态。然后P0想要读块B，先在cache中引起了读miss，然后处理器向目录发送读块B请求。目录发现块B只在P2中存在，于是只向P2发送信息。P2接收到信息后将数据给P0，并将块B状态变为Share，并向目录发送消息更新目录。

再看一个写实例，初始时P0，P2均有块B，状态为Share，且目录中保存有块B的信息。之后P0发出一个写块B的请求，cache发现块B状态为S，于是向目录发出请求，请求将其它cache中的块B无效化。目录发现P2还拥有块B，于是向P2发送无效化请求，P2无效完块B后返回确认信息给目录和P0，目录更新块B的信息，P0写块B，块B的状态也变为了Modify。

通过上面两个实例我们发现目录显著减少了互联网络上的通信流量。现在的问题是目录应该保存在哪里呢？如果像例子里一样有一个集中式的目录，那么所有处理器访问目录的带宽会是瓶颈。一种流行的方案是分布式共享存储架构DSM，可以简单理解为内存与目录是分布式的， 每一个处理器节点有几个处理器核心，cache，内存与目录的一部分。节点间采用点对点互联网络。DSM可以显著降低处理器与目录的通信流量。限于时间不展开讲DSM，如果有兴趣的话可以课下交流。

最后我们来介绍一种对目录式协议与广播侦听协议进行一些性能上的量化比较的方法。首先要选定两种协议的具体方案，然后使用真实多核处理器运行某些程序时的访存trace，之后对每一种cache操作赋予时钟周期权值，比如等待目录响应需要2周期，发送地址需要一周期。然后对trace进行具体协议的模拟，计算总cache操作个数与总时钟周期数，求一次数据移动，比如从cache1到cache2，或者cache与主存之间移动数据，所花费的时钟周期数。平均时钟周期数少的方案可能有更好的性能。

